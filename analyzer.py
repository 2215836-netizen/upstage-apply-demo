from langchain_groq import ChatGroq
from langchain_core.prompts import PromptTemplate

def analyze_strategy(news_text, api_key, model_choice=None):
    """
    Analyzes the news text using Groq (Llama 3) to generate a strategic report.
    """
    if not api_key:
        return "âš ï¸ Groq API Key is missing. Please enter it in the sidebar."
    
    if not news_text or len(news_text) < 50:
        return "âš ï¸ ë¶„ì„í•  ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."

    try:
        # Initialize LLM (Groq Llama 3.3 is the new flagship)
        llm = ChatGroq(
            model_name="llama-3.3-70b-versatile", # Latest stable model
            groq_api_key=api_key,
            temperature=0.7
        )

        template = """
        ë‹¹ì‹ ì€ ì‚¼ì„±ê¸€ë¡œë²Œë¦¬ì„œì¹˜(SGR)ì˜ **'SGR ë“œë¦¼íŒ€'**ì…ë‹ˆë‹¤. 
        ì„¸ ëª…ì˜ ì „ë¬¸ê°€(Persona)ê°€ ëª¨ì—¬ í† ë¡ í•œ ë’¤, ìµœì¢… ì „ëµ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ëŠ” ì—­í• ì„ ë§¡ì•˜ìŠµë‹ˆë‹¤.

        ---
        **[í† ë¡  ì°¸ì—¬ì]**
        1. **ğŸ‘¨â€ğŸ’¼ ê±°ì‹œê²½ì œ ì „ë¬¸ê°€ (Macro Economist)**: ê¸ˆë¦¬, í™˜ìœ¨, ì§€ì •í•™ì  ë¦¬ìŠ¤í¬, ê¸€ë¡œë²Œ ê²½ì œ íë¦„ ë¶„ì„.
        2. **ğŸ§‘â€ğŸ’» ì‚°ì—… ê¸°ìˆ  ì „ë¬¸ê°€ (Tech Specialist)**: ë°˜ë„ì²´/AI ê¸°ìˆ  íŠ¸ë Œë“œ, ê²½ìŸì‚¬(TSMC, Intel ë“±) ê¸°ìˆ  ê²©ì°¨ ë¶„ì„.
        3. **ğŸ•µï¸ ì „ëµ ì»¨ì„¤í„´íŠ¸ (Strategy Consultant)**: ìœ„ ë‘ ë¶„ì„ì„ ì¢…í•©í•˜ì—¬, ì‚¼ì„±ì „ìê°€ ë‹¹ì¥ ì‹¤í–‰í•´ì•¼ í•  **êµ¬ì²´ì  Action Plan** ë„ì¶œ.

        ---
        **[ì…ë ¥ ë‰´ìŠ¤ ë°ì´í„°]**:
        {news_content}
        ---

        ìœ„ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì„¸ ì „ë¬¸ê°€ì˜ ê´€ì ì„ í†µí•©í•˜ì—¬ **SGR ìŠ¤íƒ€ì¼ì˜ ì „ëµ ë¦¬í¬íŠ¸**ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
        ë°˜ë“œì‹œ **í•œêµ­ì–´**ë¡œ ì‘ì„±í•´ì•¼ í•˜ë©°, ì•„ë˜ í¬ë§·ì„ ì—„ê²©íˆ ì¤€ìˆ˜í•˜ì„¸ìš”:

        # ğŸ“‘ SGR ë“œë¦¼íŒ€ ì „ëµ ë¦¬í¬íŠ¸: [ì£¼ì œ í‚¤ì›Œë“œ]

        ## 1. ğŸŒ ê±°ì‹œê²½ì œ ë° ì‹œì¥ í™˜ê²½ (Macro View)
        > *"ìˆ²ì„ ë¨¼ì € ë´…ë‹ˆë‹¤." - ê±°ì‹œê²½ì œ ì „ë¬¸ê°€*
        - (í™˜ìœ¨, ê¸ˆë¦¬, êµ­ê°€ ê°„ ì •ì±… ê°ˆë“± ë“± ê±°ì‹œì  ê´€ì ì—ì„œì˜ ê¸°íšŒ/ìœ„í˜‘ ìš”ì¸ ë¶„ì„)

        ## 2. ğŸ”¬ ì‚°ì—… ë° ê¸°ìˆ  ë”¥ë‹¤ì´ë¸Œ (Tech Dive)
        > *"ê¸°ìˆ  ë””í…Œì¼ì— ì•…ë§ˆê°€ ìˆìŠµë‹ˆë‹¤." - ì‚°ì—… ê¸°ìˆ  ì „ë¬¸ê°€*
        - (ê²½ìŸì‚¬ ê¸°ìˆ  ë™í–¥, ìˆ˜ìœ¨ ë¬¸ì œ, ì°¨ì„¸ëŒ€ íŒ¨í‚¤ì§• ë“± ê¸°ìˆ ì  ê´€ì ì˜ ì‹¬ì¸µ ë¶„ì„)

        ## 3. ğŸš€ SGR ì „ëµ ì œì–¸ (Action Plan)
        > *"ê·¸ë˜ì„œ, ë‹¹ì¥ ë¬´ì—‡ì„ í•´ì•¼ í•©ë‹ˆê¹Œ?" - ì „ëµ ì»¨ì„¤í„´íŠ¸*
        - **Short-term (1ë…„ ë‚´)**: (êµ¬ì²´ì ì¸ ì‹¤í–‰ ê³¼ì œ, ì˜ˆ: ì¥ë¹„ ìˆ˜ê¸‰, íŠ¹ì • ê³ ê°ì‚¬ íƒ€ê²ŸíŒ…)
        - **Long-term (3ë…„ í›„)**: (R&D ë°©í–¥ì„±, M&A í•„ìš”ì„± ë“±)

        ## âš¡ Executive Summary (í•œ ì¤„ ìš”ì•½)
        (ë°”ìœ ì„ì›ì§„ì„ ìœ„í•œ 1ë¬¸ì¥ í•µì‹¬ ê²°ë¡ )
        
        ---
        **[ì ìˆ˜ ì‚°ì • ê¸°ì¤€ (Scoring Criteria)]**
        1. **Risk Score (0~100)**: ë°œìƒ ê°€ëŠ¥ì„± (Probability)
           - 0~30: ê°€ëŠ¥ì„± ë‚®ìŒ / ë‹¨ìˆœ ë£¨ë¨¸
           - 31~70: ê°€ëŠ¥ì„± ìˆìŒ / ì ì§„ì  ì§„í–‰
           - 71~100: í™•ì‹¤ì‹œë¨ / ì´ë¯¸ ì§„í–‰ ì¤‘ì¸ ìœ„ê¸°
        
        2. **Impact Score (0~100)**: ì˜í–¥ë ¥ ì‹¬ê°ì„± (Severity)
           - 0~30: ë‹¨ê¸°ì /êµ­ì§€ì  ì˜í–¥ (ë¬´ì‹œ ê°€ëŠ¥)
           - 31~70: ì‹¤ì /ì£¼ê°€ì— ìœ ì˜ë¯¸í•œ íƒ€ê²©
           - 71~100: ì‚¬ì—… ì¡´í ìœ„ê¸° / ê²½ì˜ì§„ ê²°ë‹¨ í•„ìš”
        
        ---
        **[System Instruction: Output JSON Data]**
        ë¦¬í¬íŠ¸ ì‘ì„±ì´ ëë‚œ í›„, ë°˜ë“œì‹œ ë§¨ ë§ˆì§€ë§‰ ì¤„ì— ì•„ë˜ í˜•ì‹ìœ¼ë¡œ **JSON ë°ì´í„° í•˜ë‚˜ë§Œ** ì¶”ê°€í•˜ì„¸ìš”.
        ì´ ì ìˆ˜ëŠ” 2x2 ë§¤íŠ¸ë¦­ìŠ¤ ì‹œê°í™”ì— ì‚¬ìš©ë©ë‹ˆë‹¤. (0~100ì )
        ê·¸ë¦¬ê³  **ì™œ ì´ ì ìˆ˜ë¥¼ ë¶€ì—¬í–ˆëŠ”ì§€ 1ë¬¸ì¥ìœ¼ë¡œ ê·¼ê±°(Reason)**ë¥¼ í•¨ê»˜ ì ìœ¼ì„¸ìš”.
        
        [[JSON_START]]
        {{
            "risk_score": 85,
            "impact_score": 90,
            "reason": "ê²½ìŸì‚¬ì˜ 3ë‚˜ë…¸ ìˆ˜ìœ¨ ì•ˆì •í™” ì†Œì‹ìœ¼ë¡œ ì¸í•´ ì ìœ ìœ¨ í•˜ë½ ìœ„í˜‘ì´ í™•ì‹¤ì‹œë¨(71ì  ì´ìƒ)."
        }}
        [[JSON_END]]
        """
        
        prompt = PromptTemplate(
            input_variables=["news_content"],
            template=template,
        )
        
        formatted_prompt = prompt.format(news_content=news_text[:15000]) # Groq handles large context well
        response = llm.invoke(formatted_prompt).content
        
        return response

    except Exception as e:
        return f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:\n{str(e)}\n\n(Tip: ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì„ ì°¾ëŠ”ë° ì‹¤íŒ¨í–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.)"
