from langchain_groq import ChatGroq
from langchain_core.prompts import PromptTemplate

def analyze_strategy(news_text, api_key, model_choice=None):
    """
    Analyzes the news text using Groq (Llama 3) to generate a strategic report.
    """
    if not api_key:
        return "âš ï¸ Groq API Key is missing. Please enter it in the sidebar."
    
    if not news_text or len(news_text) < 50:
        return "âš ï¸ ë¶„ì„í•  ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."

    try:
        # Initialize LLM (Groq Llama 3.3 is the new flagship)
        llm = ChatGroq(
            model_name="llama-3.3-70b-versatile", # Latest stable model
            groq_api_key=api_key,
            temperature=0.7
        )

        template = """
        ë‹¹ì‹ ì€ ì‚¼ì„±ê¸€ë¡œë²Œë¦¬ì„œì¹˜(SGR)ì˜ **'SGR ë“œë¦¼íŒ€'**ì…ë‹ˆë‹¤. 
        ì„¸ ëª…ì˜ ì „ë¬¸ê°€(Persona)ê°€ ëª¨ì—¬ í† ë¡ í•œ ë’¤, ìµœì¢… ì „ëµ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ëŠ” ì—­í• ì„ ë§¡ì•˜ìŠµë‹ˆë‹¤.

        ---
        **[í† ë¡  ì°¸ì—¬ì]**
        1. **ğŸ‘¨â€ğŸ’¼ ê±°ì‹œê²½ì œ ì „ë¬¸ê°€ (Macro Economist)**: ê¸ˆë¦¬, í™˜ìœ¨, ì§€ì •í•™ì  ë¦¬ìŠ¤í¬, ê¸€ë¡œë²Œ ê²½ì œ íë¦„ ë¶„ì„.
        2. **ğŸ§‘â€ğŸ’» ì‚°ì—… ê¸°ìˆ  ì „ë¬¸ê°€ (Tech Specialist)**: ë°˜ë„ì²´/AI ê¸°ìˆ  íŠ¸ë Œë“œ, ê²½ìŸì‚¬(TSMC, Intel ë“±) ê¸°ìˆ  ê²©ì°¨ ë¶„ì„.
        3. **ğŸ•µï¸ ì „ëµ ì»¨ì„¤í„´íŠ¸ (Strategy Consultant)**: ìœ„ ë‘ ë¶„ì„ì„ ì¢…í•©í•˜ì—¬, ì‚¼ì„±ì „ìê°€ ë‹¹ì¥ ì‹¤í–‰í•´ì•¼ í•  **êµ¬ì²´ì  Action Plan** ë„ì¶œ.

        ---
        **[ì…ë ¥ ë‰´ìŠ¤ ë°ì´í„°]**:
        {news_content}
        ---

        ìœ„ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì„¸ ì „ë¬¸ê°€ì˜ ê´€ì ì„ í†µí•©í•˜ì—¬ **SGR ìŠ¤íƒ€ì¼ì˜ ì „ëµ ë¦¬í¬íŠ¸**ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
        ë°˜ë“œì‹œ **í•œêµ­ì–´**ë¡œ ì‘ì„±í•´ì•¼ í•˜ë©°, ì•„ë˜ í¬ë§·ì„ ì—„ê²©íˆ ì¤€ìˆ˜í•˜ì„¸ìš”:

        # ğŸ“‘ SGR ë“œë¦¼íŒ€ ì „ëµ ë¦¬í¬íŠ¸: [ì£¼ì œ í‚¤ì›Œë“œ]

        ## 1. ğŸŒ ê±°ì‹œê²½ì œ ë° ì‹œì¥ í™˜ê²½ (Macro View)
        > *"ìˆ²ì„ ë¨¼ì € ë´…ë‹ˆë‹¤." - ê±°ì‹œê²½ì œ ì „ë¬¸ê°€*
        - (í™˜ìœ¨, ê¸ˆë¦¬, êµ­ê°€ ê°„ ì •ì±… ê°ˆë“± ë“± ê±°ì‹œì  ê´€ì ì—ì„œì˜ ê¸°íšŒ/ìœ„í˜‘ ìš”ì¸ ë¶„ì„)

        ## 2. ğŸ”¬ ì‚°ì—… ë° ê¸°ìˆ  ë”¥ë‹¤ì´ë¸Œ (Tech Dive)
        > *"ê¸°ìˆ  ë””í…Œì¼ì— ì•…ë§ˆê°€ ìˆìŠµë‹ˆë‹¤." - ì‚°ì—… ê¸°ìˆ  ì „ë¬¸ê°€*
        - (ê²½ìŸì‚¬ ê¸°ìˆ  ë™í–¥, ìˆ˜ìœ¨ ë¬¸ì œ, ì°¨ì„¸ëŒ€ íŒ¨í‚¤ì§• ë“± ê¸°ìˆ ì  ê´€ì ì˜ ì‹¬ì¸µ ë¶„ì„)

        ## 3. ğŸš€ SGR ì „ëµ ì œì–¸ (Action Plan)
        > *"ê·¸ë˜ì„œ, ë‹¹ì¥ ë¬´ì—‡ì„ í•´ì•¼ í•©ë‹ˆê¹Œ?" - ì „ëµ ì»¨ì„¤í„´íŠ¸*
        - **Short-term (1ë…„ ë‚´)**: (êµ¬ì²´ì ì¸ ì‹¤í–‰ ê³¼ì œ, ì˜ˆ: ì¥ë¹„ ìˆ˜ê¸‰, íŠ¹ì • ê³ ê°ì‚¬ íƒ€ê²ŸíŒ…)
        - **Long-term (3ë…„ í›„)**: (R&D ë°©í–¥ì„±, M&A í•„ìš”ì„± ë“±)

        ## âš¡ Executive Summary (í•œ ì¤„ ìš”ì•½)
        (ë°”ìœ ì„ì›ì§„ì„ ìœ„í•œ 1ë¬¸ì¥ í•µì‹¬ ê²°ë¡ )

        ---
        ## âš¡ Executive Summary (í•œ ì¤„ ìš”ì•½)
        (ë°”ìœ ì„ì›ì§„ì„ ìœ„í•œ 1ë¬¸ì¥ í•µì‹¬ ê²°ë¡ )

        ---
        **[ë¶„ì„ ê¸°ì¤€ (Analysis Criteria)]**
        1. **Sentiment Score (-100 ~ 100)**: ì‹œì¥ì˜ ê°ì„± (Market Sentiment)
           - -100 ~ -50: ë§¤ìš° ë¶€ì •ì  (Bearish)
           - -49 ~ 49: ì¤‘ë¦½ (Neutral)
           - 50 ~ 100: ë§¤ìš° ê¸ì •ì  (Bullish)
        
        2. **Breakdown (ê¸ì • vs ë¶€ì • ë¹„ì¤‘)**
           - ê¸°ì‚¬ ë‚´ìš© ì „ì²´ë¥¼ 100ìœ¼ë¡œ ë´¤ì„ ë•Œ, ê¸ì •ì  ë‰˜ì•™ìŠ¤ì™€ ë¶€ì •ì  ë‰˜ì•™ìŠ¤ì˜ ë¹„ìœ¨
        
        3. **Bias Score (0~100)**: ê¸°ì‚¬ì˜ í¸í–¥ì„± (Media Bias)
           - 0~30: ë§¤ìš° ì¤‘ë¦½ì /ê°ê´€ì  (Fact-based)
           - 31~70: ë‹¤ì†Œ í¸í–¥ë¨ (Opinionated)
           - 71~100: ë§¤ìš° í¸í–¥ë¨/ì„ ë™ì  (Highly Biased)

        ---
        **[System Instruction: Output JSON Data]**
        ë¦¬í¬íŠ¸ ì‘ì„±ì´ ëë‚œ í›„, ë°˜ë“œì‹œ ë§¨ ë§ˆì§€ë§‰ ì¤„ì— ì•„ë˜ í˜•ì‹ìœ¼ë¡œ **JSON ë°ì´í„° í•˜ë‚˜ë§Œ** ì¶”ê°€í•˜ì„¸ìš”.
        ì´ ë°ì´í„°ëŠ” ì‹œê°í™”ì— ì‚¬ìš©ë©ë‹ˆë‹¤.
        
        [[JSON_START]]
        {{
            "sentiment_score": 75,
            "sentiment_label": "Bullish (ê°•ì„¸)",
            "positivity_ratio": 80,
            "negativity_ratio": 20,
            "bias_score": 25,
            "bias_label": "Neutral (ì¤‘ë¦½ì )",
            "summary_reason": "AI ë°˜ë„ì²´ ìˆ˜ìš” í­ì¦ìœ¼ë¡œ ì¸í•œ ì‹¤ì  ê°œì„  ê¸°ëŒ€ê° ë°˜ì˜.",
            "positive_drivers": [
                "ì—”ë¹„ë””ì•„ H200 ì£¼ë¬¸ëŸ‰ 3ë°° ì¦ê°€",
                "ì‚¼ì„±ì „ìì˜ 3ë‚˜ë…¸ ìˆ˜ìœ¨ ê°œì„  ì†Œì‹",
                "ë¯¸êµ­ ë“± ì£¼ìš”êµ­ì˜ ë°˜ë„ì²´ ì§€ì›ê¸ˆ í™•ëŒ€"
            ],
            "negative_risks": [
                "ì§€ì •í•™ì  ë¦¬ìŠ¤í¬ë¡œ ì¸í•œ ê³µê¸‰ë§ ë¶ˆì•ˆ",
                "ì›ìì¬ ê°€ê²© ìƒìŠ¹ ì••ë°•"
            ]
        }}
        [[JSON_END]]
        """
        
        prompt = PromptTemplate(
            input_variables=["news_content"],
            template=template,
        )
        
        formatted_prompt = prompt.format(news_content=news_text[:15000]) # Groq handles large context well
        response = llm.invoke(formatted_prompt).content
        
        return response

    except Exception as e:
        return f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:\n{str(e)}\n\n(Tip: ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì„ ì°¾ëŠ”ë° ì‹¤íŒ¨í–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.)"
